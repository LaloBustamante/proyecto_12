'''
# DescripciÃ³n del proyecto  


La compaÃ±Ã­a de seguros Sure Tomorrow quiere resolver varias tareas con la ayuda de machine learning y te pide que evalÃºes esa posibilidad.

Tarea 1: encontrar clientes que sean similares a un cliente determinado. Esto ayudarÃ¡ a los agentes de la compaÃ±Ã­a con el marketing.  
Tarea 2: predecir si es probable que un nuevo cliente reciba un beneficio de seguro. Â¿Puede un modelo de predicciÃ³n entrenado funcionar mejor que un modelo dummy no entrenado? Â¿Puede funcionar peor? Explica tu respuesta.  
Tarea 3: predecir la cantidad de beneficios de seguro que probablemente recibirÃ¡ un nuevo cliente utilizando un modelo de regresiÃ³n lineal.  
Tarea 4: proteger los datos personales de los clientes sin romper el modelo de la tarea anterior.  

Es necesario desarrollar un algoritmo de transformaciÃ³n de datos que dificulte la recuperaciÃ³n de la informaciÃ³n personal si los datos caen en manos equivocadas. Esto se denomina enmascaramiento de datos u ofuscaciÃ³n de datos. Pero los datos deben protegerse de tal manera que la calidad de los modelos de machine learning no se vea afectada. No es necesario elegir el mejor modelo, basta con demostrar que el algoritmo funciona correctamente.

### Instrucciones del proyecto  

1. arga los datos.  
2. Verifica que los datos no tengan problemas: no faltan datos, no hay valores extremos, etc.  
3. Trabaja en cada tarea y responde las preguntas planteadas en la plantilla del proyecto.  
4. Saca conclusiones basadas en tu experiencia trabajando en el proyecto.  

Hay algo de cÃ³digo previo en la plantilla del proyecto, siÃ©ntete libre de usarlo. Primero se debe terminar algo de cÃ³digo previo. AdemÃ¡s, hay dos apÃ©ndices en la plantilla del proyecto con informaciÃ³n Ãºtil.  

### DescripciÃ³n de datos  

El dataset se almacena en el archivo /datasets/insurance_us.csv.  

CaracterÃ­sticas: sexo, edad, salario y nÃºmero de familiares de la persona asegurada.  
Objetivo: nÃºmero de beneficios de seguro recibidos por una persona asegurada en los Ãºltimos cinco aÃ±os.  

### EvaluaciÃ³n del proyecto  

Hemos definido los criterios de evaluaciÃ³n para el proyecto. LÃ©elos con atenciÃ³n antes de pasar al ejercicio.

Esto es en lo que se fijarÃ¡n los revisores al examinar tu proyecto:  

Â¿Seguiste todos los pasos de las instrucciones?  
Â¿Mantuviste la estructura del proyecto?  
Â¿Mantuviste el cÃ³digo ordenado?  
Â¿Desarrollaste todos los procedimientos necesarios y respondiste todas las preguntas?  
Â¿Sacaste tus conclusiones?  
'''

# InicializaciÃ³n

import math
import numpy as np
import pandas as pd

import seaborn as sns

import sklearn.linear_model
import sklearn.metrics
import sklearn.neighbors
import sklearn.preprocessing

from IPython.display import display
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.metrics import f1_score, confusion_matrix
from sklearn.model_selection import train_test_split
from sklearn.neighbors import NearestNeighbors
from sklearn.neighbors import KNeighborsClassifier
from sklearn.preprocessing import MaxAbsScaler
from sklearn.preprocessing import StandardScaler


# Carga de datos
df = pd.read_csv('/datasets/insurance_us.csv')


# Renambrado de columnas
df = df.rename(columns={'Gender': 'gender', 'Age': 'age', 'Salary': 'income', 'Family members': 'family_members', 'Insurance benefits': 'insurance_benefits'})


df.sample(10)
df.info()


# puede que queramos cambiar el tipo de edad (de float a int) aunque esto no es crucial

# escribe tu conversiÃ³n aquÃ­ si lo deseas:

# ConversiÃ³n de la columna age (edad) de float a int

df['age'] = df['age'].astype(int)


# comprueba que la conversiÃ³n se haya realizado con Ã©xito
df.info()


# ahora echa un vistazo a las estadÃ­sticas descriptivas de los datos.# Â¿Se ve todo bien?

# Mostramos estadÃ­sticas descriptivas de las columnas
df.describe()


'''
# Â¿Se ve todo bien?

Tras observar las estadÃ­sticas descriptivas, sÃ­ los datos parecen dentro de rangos normales para los seguros, no se observan valores 
extremos, faltantes o inconsistencias en los datos. Por lo que es posible proceder al anÃ¡lisis.
'''


'''
# 3  AnÃ¡lisis exploratorio de datos
Vamos a comprobar rÃ¡pidamente si existen determinados grupos de clientes observando el grÃ¡fico de pares.
'''


g = sns.pairplot(df, kind='hist')
g.fig.set_size_inches(12, 12)


'''
De acuerdo, es un poco complicado detectar grupos obvios (clÃºsteres) ya que es difÃ­cil combinar diversas variables simultÃ¡neamente (para 
analizar distribuciones multivariadas). AhÃ­ es donde LA y ML pueden ser bastante Ãºtiles.

# Tarea 1. Clientes similares

En el lenguaje de ML, es necesario desarrollar un procedimiento que devuelva los k vecinos mÃ¡s cercanos (objetos) para un objeto dado basÃ¡ndose en la distancia entre los objetos. Es posible que quieras revisar las siguientes lecciones (capÃ­tulo -> lecciÃ³n)- Distancia entre vectores -> Distancia euclidiana

* Distancia entre vectores -> Distancia Manhattan  

Para resolver la tarea, podemos probar diferentes mÃ©tricas de distancia.
'''


'''
Escribe una funciÃ³n que devuelva los k vecinos mÃ¡s cercanos para un  ğ‘›ğ‘¡â„  
  objeto basÃ¡ndose en una mÃ©trica de distancia especificada. A la hora de realizar esta tarea no debe tenerse en cuenta el nÃºmero de 
  prestaciones de   seguro recibidas. Puedes utilizar una implementaciÃ³n ya existente del algoritmo kNN de scikit-learn (consulta el 
  enlace) o tu propia implementaciÃ³n.   PruÃ©balo para cuatro combinaciones de dos casos- Escalado  

* los datos no estÃ¡n escalados  
* los datos se escalan con el escalador MaxAbsScaler  
* MÃ©tricas de distancia  
* Euclidiana  
* Manhattan  

Responde a estas preguntas:- Â¿El hecho de que los datos no estÃ©n escalados afecta al algoritmo kNN? Si es asÃ­, Â¿cÃ³mo se manifiesta?- 
Â¿QuÃ© tan similares son los resultados al utilizar la mÃ©trica de distancia Manhattan (independientemente del escalado)? 
'''


feature_names = ['gender', 'age', 'income', 'family_members']


def get_knn(df, n, k, metric):
    
    """
    Devuelve los k vecinos mÃ¡s cercanos

    :param df: DataFrame de pandas utilizado para encontrar objetos similares dentro del mismo lugar
    :param n: nÃºmero de objetos para los que se buscan los vecinos mÃ¡s cercanos    
    :param k: nÃºmero de vecinos mÃ¡s cercanos a devolver
    :param mÃ©tric: nombre de la mÃ©trica de distancia   
   
     """
# Inicializar el modelo de vecinos mÃ¡s cercanos con la mÃ©trica de distancia

    nbrs = NearestNeighbors(n_neighbors=k, metric=metric)

    # Ajustar el modelo a los datos
    nbrs.fit(df[feature_names])

# Obtener las distancias y los Ã­ndices de los k vecinos mÃ¡s cercanos
    nbrs_distances, nbrs_indices = nbrs.kneighbors([df.iloc[n][feature_names]], k, return_distance=True)
    
    # Crear un DataFrame con los resultados
    df_res = pd.concat([
        df.iloc[nbrs_indices[0]], 
        pd.DataFrame(nbrs_distances.T, index=nbrs_indices[0], columns=['distance'])
        ], axis=1)
    
    return df_res


# Escalar los datos

transformer_mas = sklearn.preprocessing.MaxAbsScaler().fit(df[feature_names].to_numpy())

# Crear un nuevo DataFrame con los datos escalados
df_scaled = df.copy()
df_scaled.loc[:, feature_names] = transformer_mas.transform(df[feature_names].to_numpy())


# Muestra aleatoria de los datos escalados
df_scaled.sample(5)


#Sin escalar y mÃ©trica Euclidiana:
print("Sin escalar, mÃ©trica Euclidiana")
result_euclidean_no_scale = get_knn(df, n=0, k=5, metric='euclidean')
display(result_euclidean_no_scale)


# Con escalado y mÃ©trica Euclidiana:
print("Con escalado, mÃ©trica Euclidiana")
result_euclidean_scaled = get_knn(df_scaled, n=0, k=5, metric='euclidean')
display(result_euclidean_scaled)


# Sin escalar y mÃ©trica Manhattan:
print("Sin escalar, mÃ©trica Manhattan")
result_manhattan_no_scale = get_knn(df, n=0, k=5, metric='manhattan')
display(result_manhattan_no_scale)


# Con escalado y mÃ©trica Manhattan:
print("Con escxalado, mÃ©trica Manhattan")
result_manhattan_scaled = get_knn(df_scaled, n=0, k=5, metric='manhattan')
display(result_manhattan_scaled)


'''
Respuestas a las preguntas

Â¿El hecho de que los datos no estÃ©n escalados afecta al algoritmo kNN? Si es asÃ­, Â¿cÃ³mo se manifiesta?

SÃ­, afecta significativamente. Sin escalado, las caracterÃ­sticas con valores mÃ¡s grandes (como los ingresos) dominan las distancias, lo 
que puede sesgar los resultados. El escalado asegura que todas las caracterÃ­sticas tengan el mismo peso en el cÃ¡lculo de la distancia.

Â¿QuÃ© tan similares son los resultados al utilizar la mÃ©trica de distancia Manhattan (independientemente del escalado)?

La mÃ©trica Manhattan suele dar resultados ligeramente diferentes a la Euclidiana, ya que mide las distancias de forma distinta (suma de 
las diferencias absolutas en lugar de las diferencias cuadradas). Sin embargo, ambas mÃ©tricas deberÃ­an ser razonablemente similares, 
especialmente cuando los datos estÃ¡n escalados.
'''


'''
# Tarea 2. Â¿Es probable que el cliente reciba una prestaciÃ³n del seguro?

En tÃ©rminos de machine learning podemos considerarlo como una tarea de clasificaciÃ³n binaria.

Con el valor de insurance_benefits superior a cero como objetivo, evalÃºa si el enfoque de clasificaciÃ³n kNN puede funcionar mejor que el modelo dummy. Instrucciones:  

* Construye un clasificador basado en KNN y mide su calidad con la mÃ©trica F1 para k=1...10 tanto para los datos originales como para los escalados. SerÃ­a interesante observar cÃ³mo k puede influir en la mÃ©trica de evaluaciÃ³n y si el escalado de los datos provoca alguna diferencia. Puedes utilizar una implementaciÃ³n ya existente del algoritmo de clasificaciÃ³n kNN de scikit-learn (consulta el enlace) o tu propia implementaciÃ³n.- Construye un modelo dummy que, en este caso, es simplemente un modelo aleatorio. DeberÃ­a devolver "1" con cierta probabilidad. Probemos el modelo con cuatro valores de probabilidad: 0, la probabilidad de pagar cualquier prestaciÃ³n del seguro, 0.5, 1. La probabilidad de pagar cualquier prestaciÃ³n del seguro puede definirse como  

ğ‘ƒ{prestaciÃ³n de seguro recibida}=nÃºmero de clientes que han recibido alguna prestaciÃ³n de seguro / nÃºmero total de clientes.  
 
Divide todos los datos correspondientes a las etapas de entrenamiento/prueba respetando la proporciÃ³n 70:30.  
'''


# # Ñalcula el objetivo (insurance_benefits_received > 0)
df['insurance_benefits_received'] = (df['insurance_benefits'] > 0).astype(int)


# comprueba el desequilibrio de clases con value_counts()

print(df['insurance_benefits_received'].value_counts())


'''
### Desequilibrio de Clases:  

Clase 0 (no recibiÃ³ prestaciÃ³n): 4436 clientes (88.7%)  
Clase 1 (recibiÃ³ prestaciÃ³n): 564 clientes (11.3%)  

ConclusiÃ³n: Hay un notable desequilibrio de clases, lo que significa que muchos mÃ¡s clientes no reciben prestaciones en comparaciÃ³n con 
aquellos que sÃ­ lo hacen.
'''


# Divide los datos en entrenamiento y prueba (70:30)

X = df[['gender', 'age', 'income', 'family_members']]
y = df['insurance_benefits_received']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)


# Escalar los datos con MaxAbsScaler

scaler = MaxAbsScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)


# FunciÃ³n para evaluar el clasificador con la mÃ©trica F1
def eval_classifier(y_true, y_pred):
    f1 = f1_score(y_true, y_pred)
    print(f'F1 Score: {f1:.2f}')
    cm = confusion_matrix(y_true, y_pred, normalize='all')
    print('Matriz de confusiÃ³n:')
    print(cm)


# Construir el modelo KNN y evaluar para k=1...10
for k in range(1, 11):
    print(f'--- k = {k} ---')
    
    # Modelo KNN con datos originales
    knn = KNeighborsClassifier(n_neighbors=k)
    knn.fit(X_train, y_train)
    y_pred = knn.predict(X_test)
    print('Datos sin escalar:')
    eval_classifier(y_test, y_pred)
    
    # Modelo KNN con datos escalados
    knn.fit(X_train_scaled, y_train)
    y_pred_scaled = knn.predict(X_test_scaled)
    print('Datos escalados:')
    eval_classifier(y_test, y_pred_scaled)


'''
### Rendimiento del Clasificador kNN:  

### Datos sin escalar:  
Los resultados muestran que el F1 Score disminuye drÃ¡sticamente a medida que aumenta el valor de k:  
Para k=1: F1 Score de 0.65  
Para k=2: F1 Score de 0.38  
Para k=10: F1 Score de 0.04  

ConclusiÃ³n: Sin escalar los datos, el modelo de kNN tiende a sobreajustarse para valores bajos de k (como k=1), pero su desempeÃ±o se 
deteriora rÃ¡pidamente a medida que k aumenta, debido a que el algoritmo no es capaz de capturar bien las diferencias en las 
caracterÃ­sticas.  

### Datos escalados:  
Los datos escalados mejoran significativamente el rendimiento del modelo kNN en todos los valores de k:  
Para k=1: F1 Score de 0.93  
Para k=10: F1 Score de 0.92  

ConclusiÃ³n: El escalado de los datos tiene un impacto positivo considerable en el rendimiento del modelo kNN. El rendimiento es mucho mÃ¡s 
estable y el F1 Score permanece alto para todos los valores de k. Esto indica que el escalado de las caracterÃ­sticas es crucial para 
algoritmos basados en la distancia como kNN.
'''


# Modelo dummy: generar la salida de un modelo aleatorio

def rnd_model_predict(P, size, seed=42):

    rng = np.random.default_rng(seed=seed)
    return rng.binomial(n=1, p=P, size=size)


# Probamos el modelo dummy con diferentes probabilidades
P_values = [0, df['insurance_benefits_received'].mean(), 0.5, 1]
for P in P_values:
    print(f'\nProbabilidad: {P:.2f}')
    y_pred_rnd = rnd_model_predict(P, len(y_test))
    eval_classifier(y_test, y_pred_rnd)
    print()


'''
### Rendimiento del Modelo Dummy:  

Probamos el modelo dummy con diferentes probabilidades (P=0, P=0.11, P=0.50, P=1), y obtuvimos los siguientes F1 Scores:

P=0: F1 Score de 0.00 (ninguna prestaciÃ³n predicha)  
P=0.11 (la proporciÃ³n real de prestaciones): F1 Score de 0.17  
P=0.50: F1 Score de 0.20  
P=1: F1 Score de 0.19 (siempre predice que se recibirÃ¡ una prestaciÃ³n)  

ConclusiÃ³n: El modelo dummy muestra que el rendimiento es bajo para todas las probabilidades probadas. El mejor resultado (F1 Score de 
0.20) se alcanza cuando se utiliza una probabilidad de 0.50, pero sigue siendo considerablemente inferior al modelo kNN con datos 
escalados.
'''


'''
En general, observamos que para los datos sin escalar, los modelos tienden a predecir un nÃºmero mucho mayor de casos negativos (clientes 
que no reciben prestaciones), lo que refleja el desequilibrio de clases.  

En los datos escalados, el modelo kNN realiza predicciones mucho mÃ¡s equilibradas, con tasas de error mÃ¡s bajas en ambas clases, lo que 
lleva a un mejor F1 Score.  

Escalado es crucial: El escalado de caracterÃ­sticas es absolutamente necesario para que el modelo kNN funcione correctamente, ya que 
mejora drÃ¡sticamente el rendimiento.  

k=1-5 son buenos valores: En general, los mejores valores de k estÃ¡n entre 1 y 5 para los datos escalados, ya que proporcionan un 
equilibrio entre precisiÃ³n y generalizaciÃ³n.  

Modelo dummy es ineficiente: El modelo dummy, incluso en su mejor configuraciÃ³n (P=0.5), tiene un desempeÃ±o muy inferior al modelo kNN. Esto demuestra que kNN es una mejor opciÃ³n para este problema de clasificaciÃ³n.
'''

'''
# Tarea 3. RegresiÃ³n (con regresiÃ³n lineal)

Con insurance_benefits como objetivo, evalÃºa cuÃ¡l serÃ­a la RECM de un modelo de regresiÃ³n lineal.

Construye tu propia implementaciÃ³n de regresiÃ³n lineal. Para ello, recuerda cÃ³mo estÃ¡ formulada la soluciÃ³n de la tarea de regresiÃ³n lineal en tÃ©rminos de LA. Comprueba la RECM tanto para los datos originales como para los escalados. Â¿Puedes ver alguna diferencia en la RECM con respecto a estos dos casos?  

Denotemos-  ğ‘‹: matriz de caracterÃ­sticas; cada fila es un caso, cada columna es una caracterÃ­stica, la primera columna estÃ¡ formada por unidades-  ğ‘¦ â€” objetivo (un vector)-  ğ‘¦Ì‚ â€” objetivo estimado (un vector)-  ğ‘¤ â€” vector de pesos La tarea de regresiÃ³n lineal en el lenguaje de las matrices puede formularse asÃ­:  

ğ‘¦=ğ‘‹ğ‘¤  

El objetivo de entrenamiento es entonces encontrar esa  ğ‘¤  w que minimice la distancia L2 (ECM) entre  ğ‘‹ğ‘¤  y ğ‘¦:  

minğ‘¤ğ‘‘2(ğ‘‹ğ‘¤,ğ‘¦) or minğ‘¤MSE(ğ‘‹ğ‘¤,ğ‘¦)  
 

Parece que hay una soluciÃ³n analÃ­tica para lo anteriormente expuesto:  

ğ‘¤=(ğ‘‹ğ‘‡ğ‘‹)âˆ’1ğ‘‹ğ‘‡ğ‘¦  
 

La fÃ³rmula anterior puede servir para encontrar los pesos  ğ‘¤ y estos Ãºltimos pueden utilizarse para calcular los valores predichos  

ğ‘¦Ì‚ =ğ‘‹ğ‘£ğ‘ğ‘™ğ‘¤  
'''


# Divide todos los datos correspondientes a las etapas de entrenamiento/prueba respetando la proporciÃ³n 70:30. Utiliza la mÃ©trica RECM para evaluar el modelo.

class MyLinearRegression:
    
    def __init__(self):
        
        self.weights = None
    
    def fit(self, X, y):
        
        # aÃ±adir las unidades
        X2 = np.append(np.ones([len(X), 1]), X, axis=1)
        # Calcular los pesos usando la fÃ³rmula de regresiÃ³n lineal (soluciÃ³n analÃ­tica)
        self.weights = np.linalg.inv(X2.T @ X2) @ X2.T @ y

    def predict(self, X):
        
        # aÃ±adir las unidades
        X2 = np.append(np.ones([len(X), 1]), X, axis=1)
        # Calcular los valores predichos (yÌ‚ = Xw)
        y_pred = X2 @ self.weights
        
        return y_pred
    

# FunciÃ³n para evaluar el modelo de regresiÃ³n
def eval_regressor(y_true, y_pred):
    
    rmse = math.sqrt(sklearn.metrics.mean_squared_error(y_true, y_pred))
    print(f'RMSE: {rmse:.2f}')
    
    r2_score = math.sqrt(sklearn.metrics.r2_score(y_true, y_pred))
    print(f'R2: {r2_score:.2f}')    


# Datos de caracterÃ­sticas y objetivo
X = df[['age', 'gender', 'income', 'family_members']].to_numpy()
y = df['insurance_benefits'].to_numpy()

# DivisiÃ³n de datos en entrenamiento y prueba (70:30)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=12345)

# Inicializar el modelo de regresiÃ³n
lr = MyLinearRegression()

# Entrenar el modelo con los datos de entrenamiento
lr.fit(X_train, y_train)

# Imprimir los pesos aprendidos
print("Pesos del modelo:", lr.weights)

# Predecir en los datos de prueba
y_test_pred = lr.predict(X_test)

# Evaluar el rendimiento del modelo en los datos de prueba
eval_regressor(y_test, y_test_pred)


'''
### Comparar el RMSE de los datos originales y escalados:  

AquÃ­ se prueba la regresiÃ³n con los datos escalados (normalizando o estandarizando las caracterÃ­sticas), para ver si hay alguna diferencia en el RMSE.
'''


# Escalado de las caracterÃ­sticas
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Dividir los datos escalados
X_train_scaled, X_test_scaled, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=12345)

# Entrenar el modelo en los datos escalados
lr.fit(X_train_scaled, y_train)

# Predecir en los datos de prueba escalados
y_test_pred_scaled = lr.predict(X_test_scaled)

# Evaluar el modelo con los datos escalados
eval_regressor(y_test, y_test_pred_scaled)


'''
### RMSE (RaÃ­z del Error CuadrÃ¡tico Medio):  

El RMSE de 0.34 indica que, en promedio, la diferencia entre los valores predichos por el modelo y los valores reales es aproximadamente 0.34 unidades. Esto implica que el modelo tiene un rendimiento razonablemente bueno para predecir la cantidad de beneficios de seguro.  

Si observamos los valores de RMSE para los datos originales y los escalados, podemos ver que ambos resultaron en un RMSE de 0.34. Esto sugiere que, en este caso especÃ­fico, el escalado no tuvo un impacto significativo en el rendimiento del modelo de regresiÃ³n. Esto puede deberse a que las caracterÃ­sticas no varÃ­an drÃ¡sticamente en magnitud y por lo tanto, el modelo es capaz de ajustarse bien incluso sin escalarlas.  

'''


'''
# Tarea 4. Ofuscar datos

Lo mejor es ofuscar los datos multiplicando las caracterÃ­sticas numÃ©ricas (recuerda que se pueden ver como la matriz  ğ‘‹) por una matriz invertible  ğ‘ƒ.  

ğ‘‹â€²=ğ‘‹Ã—ğ‘ƒ  
 

Trata de hacerlo y comprueba cÃ³mo quedarÃ¡n los valores de las caracterÃ­sticas despuÃ©s de la transformaciÃ³n. Por cierto, la propiedad de invertibilidad es importante aquÃ­, asÃ­ que asegÃºrate de que  ğ‘ƒ sea realmente invertible.  

Puedes revisar la lecciÃ³n 'Matrices y operaciones matriciales -> MultiplicaciÃ³n de matrices' para recordar la regla de multiplicaciÃ³n de matrices y su implementaciÃ³n con NumPy.  

'''


# Extraer las caracterÃ­sticas numÃ©ricas de la columna de informaciÃ³n personal
personal_info_column_list = ['gender', 'age', 'income', 'family_members']
df_pn = df[personal_info_column_list]


# Convertir a matriz NumPy
X = df_pn.to_numpy()


# Generar matriz aleatoria P
rng = np.random.default_rng(seed=42)
P = rng.random(size=(X.shape[1], X.shape[1]))


# Verificar si P es invertible calculando su determinante
if np.linalg.det(P) != 0:
    print("La matriz P es invertible.")
else:
    print("La matriz P no es invertible. Generando otra matriz.")

# Invertir la matriz para asegurarnos que podemos recuperar los datos mÃ¡s tarde
P_inv = np.linalg.inv(P)

# Transformar los datos originales
X_transformed = np.dot(X, P)

# Recuperar los datos originales
X_recovered = np.dot(X_transformed, P_inv)

# Mostrar los tres casos para algunos clientes
for i in range(3):
    print(f"Cliente {i+1}:")
    print(f"Original: {X[i]}")
    print(f"Transformado: {X_transformed[i]}")
    print(f"Recuperado: {X_recovered[i]}\n")

# Comparar los datos recuperados con los originales
difference = np.abs(X - X_recovered)
print(f"Diferencia promedio entre datos originales y recuperados: {np.mean(difference)}")


'''
Â¿Puedes adivinar la edad o los ingresos de los clientes despuÃ©s de la transformaciÃ³n?

No, despuÃ©s de aplicar la transformaciÃ³n con la matriz ğ‘ƒ, los valores de las caracterÃ­sticas (como la edad y los ingresos) se ven significativamente alterados y no tienen ninguna correlaciÃ³n directa con los valores originales, lo que los hace ininteligibles. Esto garantiza la ofuscaciÃ³n de los datos.

Â¿Puedes recuperar los datos originales de  ğ‘‹â€² si conoces  ğ‘ƒ ? Intenta comprobarlo a travÃ©s de los cÃ¡lculos moviendo  ğ‘ƒ del lado derecho de la fÃ³rmula anterior al izquierdo. En este caso las reglas de la multiplicaciÃ³n matricial son realmente Ãºtiles.

SÃ­, es posible recuperar los datos originales si conocemos la matriz P y esta es invertible. Esto se puede lograr multiplicando los datos ofuscados por la inversa de P. De esta manera, aplicamos la operaciÃ³n inversa de la transformaciÃ³n.SÃ­, puedes recuperar los datos originales multiplicando los datos transformados $ğ‘‹â€²$ por la inversa de $P(P^-1)$. Esto se debe a que $ğ‘‹â€² = ğ‘‹ Ã— ğ‘ƒ$, y cuando multiplicamos por $P^âˆ’1$, se cancela la transformaciÃ³n y obtenemos los datos originales.

Muestra los tres casos para algunos clientes- Datos originales  
  
El que estÃ¡ transformado- El que estÃ¡ invertido (recuperado)  

El cÃ³digo muestra los valores originales, los transformados, y los recuperados para tres clientes de ejemplo. Puedes ver cÃ³mo los valores se ofuscan en la transformaciÃ³n y se recuperan correctamente al aplicar la matriz inversa.

Seguramente puedes ver que algunos valores no son exactamente iguales a los de los datos originales. Â¿CuÃ¡l podrÃ­a ser la razÃ³n de ello?

Las pequeÃ±as diferencias que pueden aparecer entre los datos originales y los recuperados generalmente se deben a errores de precisiÃ³n numÃ©rica inherentes a los cÃ¡lculos con matrices en punto flotante. Aunque estas diferencias suelen ser mÃ­nimas, es algo comÃºn cuando se trabaja con matrices invertibles y operaciones de Ã¡lgebra lineal en computadoras.

'''


'''
# 4  Prueba de que la ofuscaciÃ³n de datos puede funcionar con regresiÃ³n lineal

En este proyecto la tarea de regresiÃ³n se ha resuelto con la regresiÃ³n lineal. Tu siguiente tarea es demostrar analytically que el mÃ©todo de ofuscaciÃ³n no afectarÃ¡ a la regresiÃ³n lineal en tÃ©rminos de valores predichos, es decir, que sus valores seguirÃ¡n siendo los mismos. Â¿Lo puedes creer? Pues no hace falta que lo creas, Â¡tienes que que demostrarlo!

Entonces, los datos estÃ¡n ofuscados y ahora tenemos  ğ‘‹Ã—ğ‘ƒ en lugar de tener solo  ğ‘‹. En consecuencia, hay otros pesos  ğ‘¤ğ‘ƒ como  

ğ‘¤=(ğ‘‹ğ‘‡ğ‘‹)âˆ’1ğ‘‹ğ‘‡ğ‘¦â‡’ğ‘¤ğ‘ƒ=[(ğ‘‹ğ‘ƒ)ğ‘‡ğ‘‹ğ‘ƒ]âˆ’1(ğ‘‹ğ‘ƒ)ğ‘‡ğ‘¦  
 

Â¿CÃ³mo se relacionarÃ­an  ğ‘¤ y ğ‘¤ğ‘ƒ si simplificÃ¡ramos la fÃ³rmula de  ğ‘¤ğ‘ƒ anterior?  

Â¿CuÃ¡les serÃ­an los valores predichos con  ğ‘¤ğ‘ƒ?  

Â¿QuÃ© significa esto para la calidad de la regresiÃ³n lineal si esta se mide mediante la RECM? Revisa el ApÃ©ndice B Propiedades de las matrices al final del cuaderno. Â¡AllÃ­ encontrarÃ¡s fÃ³rmulas muy Ãºtiles!  

No es necesario escribir cÃ³digo en esta secciÃ³n, basta con una explicaciÃ³n analÃ­tica.  

### Â¿CÃ³mo se relacionarÃ­an  ğ‘¤ y ğ‘¤ğ‘ƒ si simplificÃ¡ramos la fÃ³rmula de  ğ‘¤ğ‘ƒ anterior?  

Observamos que la expresiÃ³n (ğ‘‹<sup>ğ‘‡</sup>ğ‘‹)<sup>âˆ’1</sup>ğ‘‹<sup>ğ‘‡</sup>ğ‘¦ es precisamente el vector de pesos original $ğ‘¤$. Entonces, podemos expresar el vector de pesos $ğ‘¤ğ‘ƒ$ de la siguiente manera:  

ğ‘¤ğ‘ƒ=ğ‘ƒ<sup>-1</sup>ğ‘¤  

### Â¿CuÃ¡les serÃ­an los valores predichos con  ğ‘¤ğ‘ƒ?  

Los valores predichos con el nuevo modelo ofuscado serÃ­an:

$ğ‘¦â€²=ğ‘‹â€²ğ‘¤ğ‘ƒ=(ğ‘‹Ã—ğ‘ƒ)ğ‘¤ğ‘ƒy$  

Sustituyendo  ğ‘¤ğ‘ƒ=ğ‘ƒ<sup>âˆ’1</sup>:  

ğ‘¦â€²=(ğ‘‹Ã—ğ‘ƒ)(ğ‘ƒ<sup>âˆ’1</sup>ğ‘¤)  

Dado que ğ‘ƒÃ—ğ‘ƒ<sup>âˆ’1</sup>=ğ¼, tenemos:  

$ğ‘¦â€²=ğ‘‹ğ‘¤$

ConclusiÃ³n:  

Los valores predichos ğ‘¦â€² con los datos ofuscados ğ‘‹Ã—ğ‘ƒ son idÃ©nticos a los valores predichos ğ‘¦ con los datos originales ğ‘‹. Esto demuestra que la ofuscaciÃ³n no afecta en absoluto a los valores predichos por el modelo.

### Â¿QuÃ© significa esto para la calidad de la regresiÃ³n lineal si esta se mide mediante la RECM?  

Dado que los valores predichos no cambian tras la ofuscaciÃ³n de los datos, la mÃ©trica de calidad como la RECM (RaÃ­z del Error CuadrÃ¡tico Medio) tambiÃ©n permanecerÃ¡ igual. La RECM se calcula comparando los valores reales ğ‘¦ y con los valores predichos ğ‘¦', y dado que ğ‘¦â€²= y, el error seguirÃ¡ siendo el mismo, independientemente de la ofuscaciÃ³n.  

En conclusiÃ³n, la ofuscaciÃ³n mediante multiplicaciÃ³n por una matriz invertible no tiene ningÃºn efecto en los valores predichos ni en la calidad de la regresiÃ³n medida por la RECM u otras mÃ©tricas de error.

'''


'''
Prueba analÃ­tica

### DemostraciÃ³n analÃ­tica de que la ofuscaciÃ³n de datos no afecta a la regresiÃ³n lineal:  

En este ejercicio, tenemos una regresiÃ³n lineal donde los datos originales X se transforman mediante una matriz invertible P, y el objetivo es demostrar que esta ofuscaciÃ³n no afecta los valores predichos en la regresiÃ³n lineal. 

### RegresiÃ³n lineal sin ofuscaciÃ³n:  

Sabemos que el vector de pesos ğ‘¤ en una regresiÃ³n lineal se calcula utilizando la siguiente fÃ³rmula:  

ğ‘¤=(ğ‘‹<sup>ğ‘‡</sup>ğ‘‹)<sup>^âˆ’1</sup>ğ‘‹<sup>ğ‘‡</sup>ğ‘¦  

Donde:  

* X es la matriz de caracterÃ­sticas (original),  
* y es el vector objetivo (valores reales que intentamos predecir).  


RegresiÃ³n lineal con ofuscaciÃ³n:  

Si ofuscamos los datos, multiplicamos X por una matriz invertible P, obteniendo una nueva matriz de caracterÃ­sticas $ğ‘‹â€²=ğ‘‹Ã—ğ‘ƒ$. Ahora, el vector de pesos cambia a wp y se calcula de la siguiente forma:  

ğ‘¤ğ‘ƒ=((ğ‘‹Ã—ğ‘ƒ)<sup>ğ‘‡</sup>(ğ‘‹Ã—ğ‘ƒ))<sup>âˆ’1</sup>(XÃ—P)<sup>ğ‘‡</sup>y$  

Simplifiquemos esta expresiÃ³n paso a paso:  

Transpuesta del producto:  

(ğ‘‹Ã—ğ‘ƒ)<sup>ğ‘‡</sup>=ğ‘ƒ<sup>ğ‘‡</sup>ğ‘‹<sup>ğ‘‡</sup>  
 
Sustituyendo en la ecuaciÃ³n de  ğ‘¤ğ‘ƒ:  

ğ‘¤ğ‘ƒ=(ğ‘ƒ<sup>ğ‘‡</sup>ğ‘‹<sup>ğ‘‡</sup>ğ‘‹ğ‘ƒ)<sup>âˆ’1</sup>(ğ‘ƒ<sup>ğ‘‡</sup>ğ‘‹<sup>ğ‘‡</sup>ğ‘¦)  

Propiedad de la inversa de un producto de matrices:  

Sabemos que (ğ´ğµğ¶)<sup>âˆ’1</sup>=ğ¶<sup>âˆ’1</sup>ğµ<sup>âˆ’1</sup>ğ´<sup>âˆ’1</sup>, por lo que:  

ğ‘¤ğ‘ƒ=ğ‘ƒ<sup>âˆ’1</sup>(ğ‘‹<sup>ğ‘‡</sup>ğ‘‹)<sup>âˆ’1</sup>(ğ‘ƒ<sup>ğ‘‡</sup>)<sup>âˆ’1</sup>P<sup>T</sup>X<sup>T</sup>y  

Dado que: (ğ‘ƒ<sup>ğ‘‡</sup>)<sup>âˆ’1</sup>ğ‘ƒ<sup>ğ‘‡</sup>=ğ¼ (la matriz identidad), podemos simplificar aÃºn mÃ¡s:  

ğ‘¤ğ‘ƒ=ğ‘ƒ<sup>âˆ’1</sup>(ğ‘‹<sup>ğ‘‡</sup>ğ‘‹)<sup>âˆ’1</sup>ğ‘‹<sup>ğ‘‡</sup>ğ‘¦$

'''


'''
# 5  Prueba de regresiÃ³n lineal con ofuscaciÃ³n de datos

Ahora, probemos que la regresiÃ³n lineal pueda funcionar, en tÃ©rminos computacionales, con la transformaciÃ³n de ofuscaciÃ³n elegida. Construye un procedimiento o una clase que ejecute la regresiÃ³n lineal opcionalmente con la ofuscaciÃ³n. Puedes usar una implementaciÃ³n de regresiÃ³n lineal de scikit-learn o tu propia implementaciÃ³n. Ejecuta la regresiÃ³n lineal para los datos originales y los ofuscados, compara los valores predichos y los valores de las mÃ©tricas RMSE y  ğ‘…2  
 . Â¿Hay alguna diferencia?  

Procedimiento  
  
* Crea una matriz cuadrada  ğ‘ƒ de nÃºmeros aleatorios.- Comprueba que sea invertible. Si no lo es, repite el primer paso hasta obtener una matriz   
invertible.- <Â¡ tu comentario aquÃ­ !>  
* Utiliza  ğ‘‹ğ‘ƒ como la nueva matriz de caracterÃ­sticas  
'''


# Extraer las caracterÃ­sticas numÃ©ricas de la columna de informaciÃ³n personal
personal_info_column_list = ['age', 'income', 'family_members']  # Excluimos 'gender' si es categÃ³rica
df_pn = df[personal_info_column_list]

# Convertir a matriz NumPy
X = df_pn.to_numpy()
y = df['insurance_benefits'].to_numpy()

# FunciÃ³n para evaluar el modelo
def evaluate_model(X, y, description="Modelo original"):
    # Instanciar el modelo de regresiÃ³n lineal
    model = LinearRegression()
    
    # Ajustar el modelo
    model.fit(X, y)
    
    # Predecir los valores
    y_pred = model.predict(X)
    
    # Calcular las mÃ©tricas RMSE y RÂ²
    rmse = np.sqrt(mean_squared_error(y, y_pred))
    r2 = r2_score(y, y_pred)
    
    print(f"{description}:")
    print(f"RMSE: {rmse:.4f}")
    print(f"RÂ²: {r2:.4f}")
    return y_pred, rmse, r2


# Evaluar el modelo con los datos originales
y_pred_original, rmse_original, r2_original = evaluate_model(X, y, description="Modelo con datos originales")

# Generar una matriz aleatoria P
rng = np.random.default_rng(seed=42)
P = rng.random(size=(X.shape[1], X.shape[1]))

# Verificar si P es invertible calculando su determinante
while np.linalg.det(P) == 0:
    # Si P no es invertible, generar otra matriz
    P = rng.random(size=(X.shape[1], X.shape[1]))

print("La matriz P es invertible.")

# Ofuscar los datos
X_obfuscated = X @ P  # MultiplicaciÃ³n de matrices


# Evaluar el modelo con los datos ofuscados
y_pred_obfuscated, rmse_obfuscated, r2_obfuscated = evaluate_model(X_obfuscated, y, description="Modelo con datos ofuscados")

# Comparamos los resultados
print("\nComparaciÃ³n de mÃ©tricas entre datos originales y ofuscados:")
print(f"RMSE original: {rmse_original:.4f}, RMSE ofuscado: {rmse_obfuscated:.4f}")
print(f"RÂ² original: {r2_original:.4f}, RÂ² ofuscado: {r2_obfuscated:.4f}")

# Verificar que los valores predichos sean iguales (dentro de la tolerancia numÃ©rica)
if np.allclose(y_pred_original, y_pred_obfuscated):
    print("Los valores predichos son iguales para los datos originales y ofuscados.")
else:
    print("Los valores predichos son diferentes entre los datos originales y ofuscados.")


'''
# Conclusiones

PreservaciÃ³n del rendimiento del modelo:  
Los resultados obtenidos muestran que tanto el RMSE (error cuadrÃ¡tico medio) como el RÂ² (coeficiente de determinaciÃ³n) son idÃ©nticos para los modelos entrenados con los datos originales y los datos ofuscados.  
Esto confirma que la ofuscaciÃ³n de los datos no afecta el rendimiento del modelo de regresiÃ³n lineal. Las mÃ©tricas de calidad del modelo se mantienen iguales, lo que indica que las predicciones son consistentes independientemente de si los datos han sido transformados (ofuscados) o no.

Equivalencia de las predicciones:  
Los valores predichos por el modelo con los datos originales y los datos ofuscados son iguales dentro de la tolerancia numÃ©rica, lo que refuerza la conclusiÃ³n de que la ofuscaciÃ³n mediante la multiplicaciÃ³n por una matriz invertible no cambia la capacidad del modelo para realizar predicciones precisas.  

Este comportamiento se debe a que la ofuscaciÃ³n solo afecta la representaciÃ³n de los datos, pero no altera las relaciones subyacentes entre las variables independientes (caracterÃ­sticas) y la variable dependiente (objetivo).

AplicaciÃ³n efectiva de la ofuscaciÃ³n:  
La tÃ©cnica de ofuscaciÃ³n usando una matriz invertible preserva la confidencialidad de los datos originales, ya que los valores de las caracterÃ­sticas han sido transformados y no pueden ser interpretados fÃ¡cilmente sin la matriz invertida.  
Sin embargo, esta transformaciÃ³n no afecta el proceso de aprendizaje del modelo ni las predicciones, lo que hace que sea un mÃ©todo efectivo para proteger los datos mientras se mantiene la utilidad para el anÃ¡lisis de regresiÃ³n.

Impacto en la calidad de la regresiÃ³n:  
Dado que las mÃ©tricas RMSE y RÂ² son idÃ©nticas, podemos concluir que la calidad de la regresiÃ³n lineal no se ve afectada por la ofuscaciÃ³n de los datos. Esto es coherente con el anÃ¡lisis teÃ³rico realizado anteriormente, donde mostramos que la multiplicaciÃ³n por una matriz invertible no altera los resultados del ajuste del modelo.
'''

