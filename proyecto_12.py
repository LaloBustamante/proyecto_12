'''
# Descripci√≥n del proyecto  


La compa√±√≠a de seguros Sure Tomorrow quiere resolver varias tareas con la ayuda de machine learning y te pide que eval√∫es esa posibilidad.

Tarea 1: encontrar clientes que sean similares a un cliente determinado. Esto ayudar√° a los agentes de la compa√±√≠a con el marketing.  
Tarea 2: predecir si es probable que un nuevo cliente reciba un beneficio de seguro. ¬øPuede un modelo de predicci√≥n entrenado funcionar mejor que un modelo dummy no entrenado? ¬øPuede funcionar peor? Explica tu respuesta.  
Tarea 3: predecir la cantidad de beneficios de seguro que probablemente recibir√° un nuevo cliente utilizando un modelo de regresi√≥n lineal.  
Tarea 4: proteger los datos personales de los clientes sin romper el modelo de la tarea anterior.  

Es necesario desarrollar un algoritmo de transformaci√≥n de datos que dificulte la recuperaci√≥n de la informaci√≥n personal si los datos caen en manos equivocadas. Esto se denomina enmascaramiento de datos u ofuscaci√≥n de datos. Pero los datos deben protegerse de tal manera que la calidad de los modelos de machine learning no se vea afectada. No es necesario elegir el mejor modelo, basta con demostrar que el algoritmo funciona correctamente.

### Instrucciones del proyecto  

1. arga los datos.  
2. Verifica que los datos no tengan problemas: no faltan datos, no hay valores extremos, etc.  
3. Trabaja en cada tarea y responde las preguntas planteadas en la plantilla del proyecto.  
4. Saca conclusiones basadas en tu experiencia trabajando en el proyecto.  

Hay algo de c√≥digo previo en la plantilla del proyecto, si√©ntete libre de usarlo. Primero se debe terminar algo de c√≥digo previo. Adem√°s, hay dos ap√©ndices en la plantilla del proyecto con informaci√≥n √∫til.  

### Descripci√≥n de datos  

El dataset se almacena en el archivo /datasets/insurance_us.csv.  

Caracter√≠sticas: sexo, edad, salario y n√∫mero de familiares de la persona asegurada.  
Objetivo: n√∫mero de beneficios de seguro recibidos por una persona asegurada en los √∫ltimos cinco a√±os.  

### Evaluaci√≥n del proyecto  

Hemos definido los criterios de evaluaci√≥n para el proyecto. L√©elos con atenci√≥n antes de pasar al ejercicio.

Esto es en lo que se fijar√°n los revisores al examinar tu proyecto:  

¬øSeguiste todos los pasos de las instrucciones?  
¬øMantuviste la estructura del proyecto?  
¬øMantuviste el c√≥digo ordenado?  
¬øDesarrollaste todos los procedimientos necesarios y respondiste todas las preguntas?  
¬øSacaste tus conclusiones?  
'''

# Inicializaci√≥n

import math
import numpy as np
import pandas as pd

import seaborn as sns

import sklearn.linear_model
import sklearn.metrics
import sklearn.neighbors
import sklearn.preprocessing

from IPython.display import display
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.metrics import f1_score, confusion_matrix
from sklearn.model_selection import train_test_split
from sklearn.neighbors import NearestNeighbors
from sklearn.neighbors import KNeighborsClassifier
from sklearn.preprocessing import MaxAbsScaler
from sklearn.preprocessing import StandardScaler


# Carga de datos
df = pd.read_csv('/datasets/insurance_us.csv')


# Renambrado de columnas
df = df.rename(columns={'Gender': 'gender', 'Age': 'age', 'Salary': 'income', 'Family members': 'family_members', 'Insurance benefits': 'insurance_benefits'})


df.sample(10)
df.info()


# puede que queramos cambiar el tipo de edad (de float a int) aunque esto no es crucial

# escribe tu conversi√≥n aqu√≠ si lo deseas:

# Conversi√≥n de la columna age (edad) de float a int

df['age'] = df['age'].astype(int)


# comprueba que la conversi√≥n se haya realizado con √©xito
df.info()


# ahora echa un vistazo a las estad√≠sticas descriptivas de los datos.# ¬øSe ve todo bien?

# Mostramos estad√≠sticas descriptivas de las columnas
df.describe()


'''
# ¬øSe ve todo bien?

Tras observar las estad√≠sticas descriptivas, s√≠ los datos parecen dentro de rangos normales para los seguros, no se observan valores 
extremos, faltantes o inconsistencias en los datos. Por lo que es posible proceder al an√°lisis.
'''


'''
# 3  An√°lisis exploratorio de datos
Vamos a comprobar r√°pidamente si existen determinados grupos de clientes observando el gr√°fico de pares.
'''


g = sns.pairplot(df, kind='hist')
g.fig.set_size_inches(12, 12)


'''
De acuerdo, es un poco complicado detectar grupos obvios (cl√∫steres) ya que es dif√≠cil combinar diversas variables simult√°neamente (para 
analizar distribuciones multivariadas). Ah√≠ es donde LA y ML pueden ser bastante √∫tiles.

# Tarea 1. Clientes similares

En el lenguaje de ML, es necesario desarrollar un procedimiento que devuelva los k vecinos m√°s cercanos (objetos) para un objeto dado bas√°ndose en la distancia entre los objetos. Es posible que quieras revisar las siguientes lecciones (cap√≠tulo -> lecci√≥n)- Distancia entre vectores -> Distancia euclidiana

* Distancia entre vectores -> Distancia Manhattan  

Para resolver la tarea, podemos probar diferentes m√©tricas de distancia.
'''


'''
Escribe una funci√≥n que devuelva los k vecinos m√°s cercanos para un  ùëõùë°‚Ñé  
  objeto bas√°ndose en una m√©trica de distancia especificada. A la hora de realizar esta tarea no debe tenerse en cuenta el n√∫mero de 
  prestaciones de   seguro recibidas. Puedes utilizar una implementaci√≥n ya existente del algoritmo kNN de scikit-learn (consulta el 
  enlace) o tu propia implementaci√≥n.   Pru√©balo para cuatro combinaciones de dos casos- Escalado  

* los datos no est√°n escalados  
* los datos se escalan con el escalador MaxAbsScaler  
* M√©tricas de distancia  
* Euclidiana  
* Manhattan  

Responde a estas preguntas:- ¬øEl hecho de que los datos no est√©n escalados afecta al algoritmo kNN? Si es as√≠, ¬øc√≥mo se manifiesta?- 
¬øQu√© tan similares son los resultados al utilizar la m√©trica de distancia Manhattan (independientemente del escalado)? 
'''


feature_names = ['gender', 'age', 'income', 'family_members']


def get_knn(df, n, k, metric):
    
    """
    Devuelve los k vecinos m√°s cercanos

    :param df: DataFrame de pandas utilizado para encontrar objetos similares dentro del mismo lugar
    :param n: n√∫mero de objetos para los que se buscan los vecinos m√°s cercanos    
    :param k: n√∫mero de vecinos m√°s cercanos a devolver
    :param m√©tric: nombre de la m√©trica de distancia   
   
     """
# Inicializar el modelo de vecinos m√°s cercanos con la m√©trica de distancia

    nbrs = NearestNeighbors(n_neighbors=k, metric=metric)

    # Ajustar el modelo a los datos
    nbrs.fit(df[feature_names])

# Obtener las distancias y los √≠ndices de los k vecinos m√°s cercanos
    nbrs_distances, nbrs_indices = nbrs.kneighbors([df.iloc[n][feature_names]], k, return_distance=True)
    
    # Crear un DataFrame con los resultados
    df_res = pd.concat([
        df.iloc[nbrs_indices[0]], 
        pd.DataFrame(nbrs_distances.T, index=nbrs_indices[0], columns=['distance'])
        ], axis=1)
    
    return df_res


# Escalar los datos

transformer_mas = sklearn.preprocessing.MaxAbsScaler().fit(df[feature_names].to_numpy())

# Crear un nuevo DataFrame con los datos escalados
df_scaled = df.copy()
df_scaled.loc[:, feature_names] = transformer_mas.transform(df[feature_names].to_numpy())


# Muestra aleatoria de los datos escalados
df_scaled.sample(5)


#Sin escalar y m√©trica Euclidiana:
print("Sin escalar, m√©trica Euclidiana")
result_euclidean_no_scale = get_knn(df, n=0, k=5, metric='euclidean')
display(result_euclidean_no_scale)


# Con escalado y m√©trica Euclidiana:
print("Con escalado, m√©trica Euclidiana")
result_euclidean_scaled = get_knn(df_scaled, n=0, k=5, metric='euclidean')
display(result_euclidean_scaled)


# Sin escalar y m√©trica Manhattan:
print("Sin escalar, m√©trica Manhattan")
result_manhattan_no_scale = get_knn(df, n=0, k=5, metric='manhattan')
display(result_manhattan_no_scale)


# Con escalado y m√©trica Manhattan:
print("Con escxalado, m√©trica Manhattan")
result_manhattan_scaled = get_knn(df_scaled, n=0, k=5, metric='manhattan')
display(result_manhattan_scaled)


'''
Respuestas a las preguntas

¬øEl hecho de que los datos no est√©n escalados afecta al algoritmo kNN? Si es as√≠, ¬øc√≥mo se manifiesta?

S√≠, afecta significativamente. Sin escalado, las caracter√≠sticas con valores m√°s grandes (como los ingresos) dominan las distancias, lo 
que puede sesgar los resultados. El escalado asegura que todas las caracter√≠sticas tengan el mismo peso en el c√°lculo de la distancia.

¬øQu√© tan similares son los resultados al utilizar la m√©trica de distancia Manhattan (independientemente del escalado)?

La m√©trica Manhattan suele dar resultados ligeramente diferentes a la Euclidiana, ya que mide las distancias de forma distinta (suma de 
las diferencias absolutas en lugar de las diferencias cuadradas). Sin embargo, ambas m√©tricas deber√≠an ser razonablemente similares, 
especialmente cuando los datos est√°n escalados.
'''


'''
# Tarea 2. ¬øEs probable que el cliente reciba una prestaci√≥n del seguro?

En t√©rminos de machine learning podemos considerarlo como una tarea de clasificaci√≥n binaria.

Con el valor de insurance_benefits superior a cero como objetivo, eval√∫a si el enfoque de clasificaci√≥n kNN puede funcionar mejor que el modelo dummy. Instrucciones:  

* Construye un clasificador basado en KNN y mide su calidad con la m√©trica F1 para k=1...10 tanto para los datos originales como para los escalados. Ser√≠a interesante observar c√≥mo k puede influir en la m√©trica de evaluaci√≥n y si el escalado de los datos provoca alguna diferencia. Puedes utilizar una implementaci√≥n ya existente del algoritmo de clasificaci√≥n kNN de scikit-learn (consulta el enlace) o tu propia implementaci√≥n.- Construye un modelo dummy que, en este caso, es simplemente un modelo aleatorio. Deber√≠a devolver "1" con cierta probabilidad. Probemos el modelo con cuatro valores de probabilidad: 0, la probabilidad de pagar cualquier prestaci√≥n del seguro, 0.5, 1. La probabilidad de pagar cualquier prestaci√≥n del seguro puede definirse como  

ùëÉ{prestaci√≥n de seguro recibida}=n√∫mero de clientes que han recibido alguna prestaci√≥n de seguro / n√∫mero total de clientes.  
 
Divide todos los datos correspondientes a las etapas de entrenamiento/prueba respetando la proporci√≥n 70:30.  
'''


# # —Åalcula el objetivo (insurance_benefits_received > 0)
df['insurance_benefits_received'] = (df['insurance_benefits'] > 0).astype(int)


# comprueba el desequilibrio de clases con value_counts()

print(df['insurance_benefits_received'].value_counts())


'''
### Desequilibrio de Clases:  

Clase 0 (no recibi√≥ prestaci√≥n): 4436 clientes (88.7%)  
Clase 1 (recibi√≥ prestaci√≥n): 564 clientes (11.3%)  

Conclusi√≥n: Hay un notable desequilibrio de clases, lo que significa que muchos m√°s clientes no reciben prestaciones en comparaci√≥n con 
aquellos que s√≠ lo hacen.
'''


# Divide los datos en entrenamiento y prueba (70:30)

X = df[['gender', 'age', 'income', 'family_members']]
y = df['insurance_benefits_received']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)


# Escalar los datos con MaxAbsScaler

scaler = MaxAbsScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)


# Funci√≥n para evaluar el clasificador con la m√©trica F1
def eval_classifier(y_true, y_pred):
    f1 = f1_score(y_true, y_pred)
    print(f'F1 Score: {f1:.2f}')
    cm = confusion_matrix(y_true, y_pred, normalize='all')
    print('Matriz de confusi√≥n:')
    print(cm)


# Construir el modelo KNN y evaluar para k=1...10
for k in range(1, 11):
    print(f'--- k = {k} ---')
    
    # Modelo KNN con datos originales
    knn = KNeighborsClassifier(n_neighbors=k)
    knn.fit(X_train, y_train)
    y_pred = knn.predict(X_test)
    print('Datos sin escalar:')
    eval_classifier(y_test, y_pred)
    
    # Modelo KNN con datos escalados
    knn.fit(X_train_scaled, y_train)
    y_pred_scaled = knn.predict(X_test_scaled)
    print('Datos escalados:')
    eval_classifier(y_test, y_pred_scaled)


'''
### Rendimiento del Clasificador kNN:  

### Datos sin escalar:  
Los resultados muestran que el F1 Score disminuye dr√°sticamente a medida que aumenta el valor de k:  
Para k=1: F1 Score de 0.65  
Para k=2: F1 Score de 0.38  
Para k=10: F1 Score de 0.04  

Conclusi√≥n: Sin escalar los datos, el modelo de kNN tiende a sobreajustarse para valores bajos de k (como k=1), pero su desempe√±o se 
deteriora r√°pidamente a medida que k aumenta, debido a que el algoritmo no es capaz de capturar bien las diferencias en las 
caracter√≠sticas.  

### Datos escalados:  
Los datos escalados mejoran significativamente el rendimiento del modelo kNN en todos los valores de k:  
Para k=1: F1 Score de 0.93  
Para k=10: F1 Score de 0.92  

Conclusi√≥n: El escalado de los datos tiene un impacto positivo considerable en el rendimiento del modelo kNN. El rendimiento es mucho m√°s 
estable y el F1 Score permanece alto para todos los valores de k. Esto indica que el escalado de las caracter√≠sticas es crucial para 
algoritmos basados en la distancia como kNN.
'''


# Modelo dummy: generar la salida de un modelo aleatorio

def rnd_model_predict(P, size, seed=42):

    rng = np.random.default_rng(seed=seed)
    return rng.binomial(n=1, p=P, size=size)


# Probamos el modelo dummy con diferentes probabilidades
P_values = [0, df['insurance_benefits_received'].mean(), 0.5, 1]
for P in P_values:
    print(f'\nProbabilidad: {P:.2f}')
    y_pred_rnd = rnd_model_predict(P, len(y_test))
    eval_classifier(y_test, y_pred_rnd)
    print()


'''
### Rendimiento del Modelo Dummy:  

Probamos el modelo dummy con diferentes probabilidades (P=0, P=0.11, P=0.50, P=1), y obtuvimos los siguientes F1 Scores:

P=0: F1 Score de 0.00 (ninguna prestaci√≥n predicha)  
P=0.11 (la proporci√≥n real de prestaciones): F1 Score de 0.17  
P=0.50: F1 Score de 0.20  
P=1: F1 Score de 0.19 (siempre predice que se recibir√° una prestaci√≥n)  

Conclusi√≥n: El modelo dummy muestra que el rendimiento es bajo para todas las probabilidades probadas. El mejor resultado (F1 Score de 
0.20) se alcanza cuando se utiliza una probabilidad de 0.50, pero sigue siendo considerablemente inferior al modelo kNN con datos 
escalados.
'''


'''
En general, observamos que para los datos sin escalar, los modelos tienden a predecir un n√∫mero mucho mayor de casos negativos (clientes 
que no reciben prestaciones), lo que refleja el desequilibrio de clases.  

En los datos escalados, el modelo kNN realiza predicciones mucho m√°s equilibradas, con tasas de error m√°s bajas en ambas clases, lo que 
lleva a un mejor F1 Score.  

Escalado es crucial: El escalado de caracter√≠sticas es absolutamente necesario para que el modelo kNN funcione correctamente, ya que 
mejora dr√°sticamente el rendimiento.  

k=1-5 son buenos valores: En general, los mejores valores de k est√°n entre 1 y 5 para los datos escalados, ya que proporcionan un 
equilibrio entre precisi√≥n y generalizaci√≥n.  

Modelo dummy es ineficiente: El modelo dummy, incluso en su mejor configuraci√≥n (P=0.5), tiene un desempe√±o muy inferior al modelo kNN. Esto demuestra que kNN es una mejor opci√≥n para este problema de clasificaci√≥n.
'''

'''
# Tarea 3. Regresi√≥n (con regresi√≥n lineal)

Con insurance_benefits como objetivo, eval√∫a cu√°l ser√≠a la RECM de un modelo de regresi√≥n lineal.

Construye tu propia implementaci√≥n de regresi√≥n lineal. Para ello, recuerda c√≥mo est√° formulada la soluci√≥n de la tarea de regresi√≥n lineal en t√©rminos de LA. Comprueba la RECM tanto para los datos originales como para los escalados. ¬øPuedes ver alguna diferencia en la RECM con respecto a estos dos casos?  

Denotemos-  ùëã: matriz de caracter√≠sticas; cada fila es un caso, cada columna es una caracter√≠stica, la primera columna est√° formada por unidades-  ùë¶ ‚Äî objetivo (un vector)-  ùë¶ÃÇ ‚Äî objetivo estimado (un vector)-  ùë§ ‚Äî vector de pesos La tarea de regresi√≥n lineal en el lenguaje de las matrices puede formularse as√≠:  

ùë¶=ùëãùë§  

El objetivo de entrenamiento es entonces encontrar esa  ùë§  w que minimice la distancia L2 (ECM) entre  ùëãùë§  y ùë¶:  

minùë§ùëë2(ùëãùë§,ùë¶) or minùë§MSE(ùëãùë§,ùë¶)  
 

Parece que hay una soluci√≥n anal√≠tica para lo anteriormente expuesto:  

ùë§=(ùëãùëáùëã)‚àí1ùëãùëáùë¶  
 

La f√≥rmula anterior puede servir para encontrar los pesos  ùë§ y estos √∫ltimos pueden utilizarse para calcular los valores predichos  

ùë¶ÃÇ =ùëãùë£ùëéùëôùë§  
'''


# Divide todos los datos correspondientes a las etapas de entrenamiento/prueba respetando la proporci√≥n 70:30. Utiliza la m√©trica RECM para evaluar el modelo.

class MyLinearRegression:
    
    def __init__(self):
        
        self.weights = None
    
    def fit(self, X, y):
        
        # a√±adir las unidades
        X2 = np.append(np.ones([len(X), 1]), X, axis=1)
        # Calcular los pesos usando la f√≥rmula de regresi√≥n lineal (soluci√≥n anal√≠tica)
        self.weights = np.linalg.inv(X2.T @ X2) @ X2.T @ y

    def predict(self, X):
        
        # a√±adir las unidades
        X2 = np.append(np.ones([len(X), 1]), X, axis=1)
        # Calcular los valores predichos (yÃÇ = Xw)
        y_pred = X2 @ self.weights
        
        return y_pred
    

# Funci√≥n para evaluar el modelo de regresi√≥n
def eval_regressor(y_true, y_pred):
    
    rmse = math.sqrt(sklearn.metrics.mean_squared_error(y_true, y_pred))
    print(f'RMSE: {rmse:.2f}')
    
    r2_score = math.sqrt(sklearn.metrics.r2_score(y_true, y_pred))
    print(f'R2: {r2_score:.2f}')    


# Datos de caracter√≠sticas y objetivo
X = df[['age', 'gender', 'income', 'family_members']].to_numpy()
y = df['insurance_benefits'].to_numpy()

# Divisi√≥n de datos en entrenamiento y prueba (70:30)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=12345)

# Inicializar el modelo de regresi√≥n
lr = MyLinearRegression()

# Entrenar el modelo con los datos de entrenamiento
lr.fit(X_train, y_train)

# Imprimir los pesos aprendidos
print("Pesos del modelo:", lr.weights)

# Predecir en los datos de prueba
y_test_pred = lr.predict(X_test)

# Evaluar el rendimiento del modelo en los datos de prueba
eval_regressor(y_test, y_test_pred)


'''
### Comparar el RMSE de los datos originales y escalados:  

Aqu√≠ se prueba la regresi√≥n con los datos escalados (normalizando o estandarizando las caracter√≠sticas), para ver si hay alguna diferencia en el RMSE.
'''


# Escalado de las caracter√≠sticas
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Dividir los datos escalados
X_train_scaled, X_test_scaled, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=12345)

# Entrenar el modelo en los datos escalados
lr.fit(X_train_scaled, y_train)

# Predecir en los datos de prueba escalados
y_test_pred_scaled = lr.predict(X_test_scaled)

# Evaluar el modelo con los datos escalados
eval_regressor(y_test, y_test_pred_scaled)


'''
### RMSE (Ra√≠z del Error Cuadr√°tico Medio):  

El RMSE de 0.34 indica que, en promedio, la diferencia entre los valores predichos por el modelo y los valores reales es aproximadamente 0.34 unidades. Esto implica que el modelo tiene un rendimiento razonablemente bueno para predecir la cantidad de beneficios de seguro.  

Si observamos los valores de RMSE para los datos originales y los escalados, podemos ver que ambos resultaron en un RMSE de 0.34. Esto sugiere que, en este caso espec√≠fico, el escalado no tuvo un impacto significativo en el rendimiento del modelo de regresi√≥n. Esto puede deberse a que las caracter√≠sticas no var√≠an dr√°sticamente en magnitud y por lo tanto, el modelo es capaz de ajustarse bien incluso sin escalarlas.  

'''


'''
# Tarea 4. Ofuscar datos

Lo mejor es ofuscar los datos multiplicando las caracter√≠sticas num√©ricas (recuerda que se pueden ver como la matriz  ùëã) por una matriz invertible  ùëÉ.  

ùëã‚Ä≤=ùëã√óùëÉ  
 

Trata de hacerlo y comprueba c√≥mo quedar√°n los valores de las caracter√≠sticas despu√©s de la transformaci√≥n. Por cierto, la propiedad de invertibilidad es importante aqu√≠, as√≠ que aseg√∫rate de que  ùëÉ sea realmente invertible.  

Puedes revisar la lecci√≥n 'Matrices y operaciones matriciales -> Multiplicaci√≥n de matrices' para recordar la regla de multiplicaci√≥n de matrices y su implementaci√≥n con NumPy.  

'''


# Extraer las caracter√≠sticas num√©ricas de la columna de informaci√≥n personal
personal_info_column_list = ['gender', 'age', 'income', 'family_members']
df_pn = df[personal_info_column_list]


# Convertir a matriz NumPy
X = df_pn.to_numpy()


# Generar matriz aleatoria P
rng = np.random.default_rng(seed=42)
P = rng.random(size=(X.shape[1], X.shape[1]))


# Verificar si P es invertible calculando su determinante
if np.linalg.det(P) != 0:
    print("La matriz P es invertible.")
else:
    print("La matriz P no es invertible. Generando otra matriz.")

# Invertir la matriz para asegurarnos que podemos recuperar los datos m√°s tarde
P_inv = np.linalg.inv(P)

# Transformar los datos originales
X_transformed = np.dot(X, P)

# Recuperar los datos originales
X_recovered = np.dot(X_transformed, P_inv)

# Mostrar los tres casos para algunos clientes
for i in range(3):
    print(f"Cliente {i+1}:")
    print(f"Original: {X[i]}")
    print(f"Transformado: {X_transformed[i]}")
    print(f"Recuperado: {X_recovered[i]}\n")

# Comparar los datos recuperados con los originales
difference = np.abs(X - X_recovered)
print(f"Diferencia promedio entre datos originales y recuperados: {np.mean(difference)}")


'''
¬øPuedes adivinar la edad o los ingresos de los clientes despu√©s de la transformaci√≥n?

No, despu√©s de aplicar la transformaci√≥n con la matriz ùëÉ, los valores de las caracter√≠sticas (como la edad y los ingresos) se ven significativamente alterados y no tienen ninguna correlaci√≥n directa con los valores originales, lo que los hace ininteligibles. Esto garantiza la ofuscaci√≥n de los datos.

¬øPuedes recuperar los datos originales de  ùëã‚Ä≤ si conoces  ùëÉ ? Intenta comprobarlo a trav√©s de los c√°lculos moviendo  ùëÉ del lado derecho de la f√≥rmula anterior al izquierdo. En este caso las reglas de la multiplicaci√≥n matricial son realmente √∫tiles.

S√≠, es posible recuperar los datos originales si conocemos la matriz P y esta es invertible. Esto se puede lograr multiplicando los datos ofuscados por la inversa de P. De esta manera, aplicamos la operaci√≥n inversa de la transformaci√≥n.S√≠, puedes recuperar los datos originales multiplicando los datos transformados $ùëã‚Ä≤$ por la inversa de $P(P^-1)$. Esto se debe a que $ùëã‚Ä≤ = ùëã √ó ùëÉ$, y cuando multiplicamos por $P^‚àí1$, se cancela la transformaci√≥n y obtenemos los datos originales.

Muestra los tres casos para algunos clientes- Datos originales  
  
El que est√° transformado- El que est√° invertido (recuperado)  

El c√≥digo muestra los valores originales, los transformados, y los recuperados para tres clientes de ejemplo. Puedes ver c√≥mo los valores se ofuscan en la transformaci√≥n y se recuperan correctamente al aplicar la matriz inversa.

Seguramente puedes ver que algunos valores no son exactamente iguales a los de los datos originales. ¬øCu√°l podr√≠a ser la raz√≥n de ello?

Las peque√±as diferencias que pueden aparecer entre los datos originales y los recuperados generalmente se deben a errores de precisi√≥n num√©rica inherentes a los c√°lculos con matrices en punto flotante. Aunque estas diferencias suelen ser m√≠nimas, es algo com√∫n cuando se trabaja con matrices invertibles y operaciones de √°lgebra lineal en computadoras.

'''


'''
# 4  Prueba de que la ofuscaci√≥n de datos puede funcionar con regresi√≥n lineal

En este proyecto la tarea de regresi√≥n se ha resuelto con la regresi√≥n lineal. Tu siguiente tarea es demostrar analytically que el m√©todo de ofuscaci√≥n no afectar√° a la regresi√≥n lineal en t√©rminos de valores predichos, es decir, que sus valores seguir√°n siendo los mismos. ¬øLo puedes creer? Pues no hace falta que lo creas, ¬°tienes que que demostrarlo!

Entonces, los datos est√°n ofuscados y ahora tenemos  ùëã√óùëÉ en lugar de tener solo  ùëã. En consecuencia, hay otros pesos  ùë§ùëÉ como  

ùë§=(ùëãùëáùëã)‚àí1ùëãùëáùë¶‚áíùë§ùëÉ=[(ùëãùëÉ)ùëáùëãùëÉ]‚àí1(ùëãùëÉ)ùëáùë¶  
 

¬øC√≥mo se relacionar√≠an  ùë§ y ùë§ùëÉ si simplific√°ramos la f√≥rmula de  ùë§ùëÉ anterior?  

¬øCu√°les ser√≠an los valores predichos con  ùë§ùëÉ?  

¬øQu√© significa esto para la calidad de la regresi√≥n lineal si esta se mide mediante la RECM? Revisa el Ap√©ndice B Propiedades de las matrices al final del cuaderno. ¬°All√≠ encontrar√°s f√≥rmulas muy √∫tiles!  

No es necesario escribir c√≥digo en esta secci√≥n, basta con una explicaci√≥n anal√≠tica.  

### ¬øC√≥mo se relacionar√≠an  ùë§ y ùë§ùëÉ si simplific√°ramos la f√≥rmula de  ùë§ùëÉ anterior?  

Observamos que la expresi√≥n (ùëã<sup>ùëá</sup>ùëã)<sup>‚àí1</sup>ùëã<sup>ùëá</sup>ùë¶ es precisamente el vector de pesos original $ùë§$. Entonces, podemos expresar el vector de pesos $ùë§ùëÉ$ de la siguiente manera:  

ùë§ùëÉ=ùëÉ<sup>-1</sup>ùë§  

### ¬øCu√°les ser√≠an los valores predichos con  ùë§ùëÉ?  

Los valores predichos con el nuevo modelo ofuscado ser√≠an:

$ùë¶‚Ä≤=ùëã‚Ä≤ùë§ùëÉ=(ùëã√óùëÉ)ùë§ùëÉy$  

Sustituyendo  ùë§ùëÉ=ùëÉ<sup>‚àí1</sup>:  

ùë¶‚Ä≤=(ùëã√óùëÉ)(ùëÉ<sup>‚àí1</sup>ùë§)  

Dado que ùëÉ√óùëÉ<sup>‚àí1</sup>=ùêº, tenemos:  

$ùë¶‚Ä≤=ùëãùë§$

Conclusi√≥n:  

Los valores predichos ùë¶‚Ä≤ con los datos ofuscados ùëã√óùëÉ son id√©nticos a los valores predichos ùë¶ con los datos originales ùëã. Esto demuestra que la ofuscaci√≥n no afecta en absoluto a los valores predichos por el modelo.

### ¬øQu√© significa esto para la calidad de la regresi√≥n lineal si esta se mide mediante la RECM?  

Dado que los valores predichos no cambian tras la ofuscaci√≥n de los datos, la m√©trica de calidad como la RECM (Ra√≠z del Error Cuadr√°tico Medio) tambi√©n permanecer√° igual. La RECM se calcula comparando los valores reales ùë¶ y con los valores predichos ùë¶', y dado que ùë¶‚Ä≤= y, el error seguir√° siendo el mismo, independientemente de la ofuscaci√≥n.  

En conclusi√≥n, la ofuscaci√≥n mediante multiplicaci√≥n por una matriz invertible no tiene ning√∫n efecto en los valores predichos ni en la calidad de la regresi√≥n medida por la RECM u otras m√©tricas de error.

'''


'''
Prueba anal√≠tica

### Demostraci√≥n anal√≠tica de que la ofuscaci√≥n de datos no afecta a la regresi√≥n lineal:  

En este ejercicio, tenemos una regresi√≥n lineal donde los datos originales X se transforman mediante una matriz invertible P, y el objetivo es demostrar que esta ofuscaci√≥n no afecta los valores predichos en la regresi√≥n lineal. 

### Regresi√≥n lineal sin ofuscaci√≥n:  

Sabemos que el vector de pesos ùë§ en una regresi√≥n lineal se calcula utilizando la siguiente f√≥rmula:  

ùë§=(ùëã<sup>ùëá</sup>ùëã)<sup>^‚àí1</sup>ùëã<sup>ùëá</sup>ùë¶  

Donde:  

* X es la matriz de caracter√≠sticas (original),  
* y es el vector objetivo (valores reales que intentamos predecir).  


Regresi√≥n lineal con ofuscaci√≥n:  

Si ofuscamos los datos, multiplicamos X por una matriz invertible P, obteniendo una nueva matriz de caracter√≠sticas $ùëã‚Ä≤=ùëã√óùëÉ$. Ahora, el vector de pesos cambia a wp y se calcula de la siguiente forma:  

ùë§ùëÉ=((ùëã√óùëÉ)<sup>ùëá</sup>(ùëã√óùëÉ))<sup>‚àí1</sup>(X√óP)<sup>ùëá</sup>y$  

Simplifiquemos esta expresi√≥n paso a paso:  

Transpuesta del producto:  

(ùëã√óùëÉ)<sup>ùëá</sup>=ùëÉ<sup>ùëá</sup>ùëã<sup>ùëá</sup>  
 
Sustituyendo en la ecuaci√≥n de  ùë§ùëÉ:  

ùë§ùëÉ=(ùëÉ<sup>ùëá</sup>ùëã<sup>ùëá</sup>ùëãùëÉ)<sup>‚àí1</sup>(ùëÉ<sup>ùëá</sup>ùëã<sup>ùëá</sup>ùë¶)  

Propiedad de la inversa de un producto de matrices:  

Sabemos que (ùê¥ùêµùê∂)<sup>‚àí1</sup>=ùê∂<sup>‚àí1</sup>ùêµ<sup>‚àí1</sup>ùê¥<sup>‚àí1</sup>, por lo que:  

ùë§ùëÉ=ùëÉ<sup>‚àí1</sup>(ùëã<sup>ùëá</sup>ùëã)<sup>‚àí1</sup>(ùëÉ<sup>ùëá</sup>)<sup>‚àí1</sup>P<sup>T</sup>X<sup>T</sup>y  

Dado que: (ùëÉ<sup>ùëá</sup>)<sup>‚àí1</sup>ùëÉ<sup>ùëá</sup>=ùêº (la matriz identidad), podemos simplificar a√∫n m√°s:  

ùë§ùëÉ=ùëÉ<sup>‚àí1</sup>(ùëã<sup>ùëá</sup>ùëã)<sup>‚àí1</sup>ùëã<sup>ùëá</sup>ùë¶$

'''


'''
# 5  Prueba de regresi√≥n lineal con ofuscaci√≥n de datos

Ahora, probemos que la regresi√≥n lineal pueda funcionar, en t√©rminos computacionales, con la transformaci√≥n de ofuscaci√≥n elegida. Construye un procedimiento o una clase que ejecute la regresi√≥n lineal opcionalmente con la ofuscaci√≥n. Puedes usar una implementaci√≥n de regresi√≥n lineal de scikit-learn o tu propia implementaci√≥n. Ejecuta la regresi√≥n lineal para los datos originales y los ofuscados, compara los valores predichos y los valores de las m√©tricas RMSE y  ùëÖ2  
 . ¬øHay alguna diferencia?  

Procedimiento  
  
* Crea una matriz cuadrada  ùëÉ de n√∫meros aleatorios.- Comprueba que sea invertible. Si no lo es, repite el primer paso hasta obtener una matriz   
invertible.- <¬° tu comentario aqu√≠ !>  
* Utiliza  ùëãùëÉ como la nueva matriz de caracter√≠sticas  
'''


# Extraer las caracter√≠sticas num√©ricas de la columna de informaci√≥n personal
personal_info_column_list = ['age', 'income', 'family_members']  # Excluimos 'gender' si es categ√≥rica
df_pn = df[personal_info_column_list]

# Convertir a matriz NumPy
X = df_pn.to_numpy()
y = df['insurance_benefits'].to_numpy()

# Funci√≥n para evaluar el modelo
def evaluate_model(X, y, description="Modelo original"):
    # Instanciar el modelo de regresi√≥n lineal
    model = LinearRegression()
    
    # Ajustar el modelo
    model.fit(X, y)
    
    # Predecir los valores
    y_pred = model.predict(X)
    
    # Calcular las m√©tricas RMSE y R¬≤
    rmse = np.sqrt(mean_squared_error(y, y_pred))
    r2 = r2_score(y, y_pred)
    
    print(f"{description}:")
    print(f"RMSE: {rmse:.4f}")
    print(f"R¬≤: {r2:.4f}")
    return y_pred, rmse, r2


# Evaluar el modelo con los datos originales
y_pred_original, rmse_original, r2_original = evaluate_model(X, y, description="Modelo con datos originales")

# Generar una matriz aleatoria P
rng = np.random.default_rng(seed=42)
P = rng.random(size=(X.shape[1], X.shape[1]))

# Verificar si P es invertible calculando su determinante
while np.linalg.det(P) == 0:
    # Si P no es invertible, generar otra matriz
    P = rng.random(size=(X.shape[1], X.shape[1]))

print("La matriz P es invertible.")

# Ofuscar los datos
X_obfuscated = X @ P  # Multiplicaci√≥n de matrices


# Evaluar el modelo con los datos ofuscados
y_pred_obfuscated, rmse_obfuscated, r2_obfuscated = evaluate_model(X_obfuscated, y, description="Modelo con datos ofuscados")

# Comparamos los resultados
print("\nComparaci√≥n de m√©tricas entre datos originales y ofuscados:")
print(f"RMSE original: {rmse_original:.4f}, RMSE ofuscado: {rmse_obfuscated:.4f}")
print(f"R¬≤ original: {r2_original:.4f}, R¬≤ ofuscado: {r2_obfuscated:.4f}")

# Verificar que los valores predichos sean iguales (dentro de la tolerancia num√©rica)
if np.allclose(y_pred_original, y_pred_obfuscated):
    print("Los valores predichos son iguales para los datos originales y ofuscados.")
else:
    print("Los valores predichos son diferentes entre los datos originales y ofuscados.")


'''
# Conclusiones

Preservaci√≥n del rendimiento del modelo:  
Los resultados obtenidos muestran que tanto el RMSE (error cuadr√°tico medio) como el R¬≤ (coeficiente de determinaci√≥n) son id√©nticos para los modelos entrenados con los datos originales y los datos ofuscados.  
Esto confirma que la ofuscaci√≥n de los datos no afecta el rendimiento del modelo de regresi√≥n lineal. Las m√©tricas de calidad del modelo se mantienen iguales, lo que indica que las predicciones son consistentes independientemente de si los datos han sido transformados (ofuscados) o no.

Equivalencia de las predicciones:  
Los valores predichos por el modelo con los datos originales y los datos ofuscados son iguales dentro de la tolerancia num√©rica, lo que refuerza la conclusi√≥n de que la ofuscaci√≥n mediante la multiplicaci√≥n por una matriz invertible no cambia la capacidad del modelo para realizar predicciones precisas.  

Este comportamiento se debe a que la ofuscaci√≥n solo afecta la representaci√≥n de los datos, pero no altera las relaciones subyacentes entre las variables independientes (caracter√≠sticas) y la variable dependiente (objetivo).

Aplicaci√≥n efectiva de la ofuscaci√≥n:  
La t√©cnica de ofuscaci√≥n usando una matriz invertible preserva la confidencialidad de los datos originales, ya que los valores de las caracter√≠sticas han sido transformados y no pueden ser interpretados f√°cilmente sin la matriz invertida.  
Sin embargo, esta transformaci√≥n no afecta el proceso de aprendizaje del modelo ni las predicciones, lo que hace que sea un m√©todo efectivo para proteger los datos mientras se mantiene la utilidad para el an√°lisis de regresi√≥n.

Impacto en la calidad de la regresi√≥n:  
Dado que las m√©tricas RMSE y R¬≤ son id√©nticas, podemos concluir que la calidad de la regresi√≥n lineal no se ve afectada por la ofuscaci√≥n de los datos. Esto es coherente con el an√°lisis te√≥rico realizado anteriormente, donde mostramos que la multiplicaci√≥n por una matriz invertible no altera los resultados del ajuste del modelo.
'''

